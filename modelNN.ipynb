{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding,SimpleRNN, LSTM, Activation, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('train_preprocess.tsv.txt',sep='\\t', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the column\n",
    "df.rename(columns = {0:'text', 1:'labels' }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    6416\n",
       "negative    3436\n",
       "neutral     1148\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db = sqlite3.connect('challenge.db')\n",
    "mycursor = db.cursor()\n",
    "query = \"CREATE TABLE IF NOT EXISTS Table_1 (text varchar(255), label varchar(255));\"\n",
    "mycursor.execute(query)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleansing\n",
    "import re\n",
    "\n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n','', text)\n",
    "    text = re.sub('rt','', text)\n",
    "    text = re.sub('user','', text)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text)\n",
    "    text = re.sub('  +',' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text)\n",
    "    text = re.sub('  +',' ', text) \n",
    "    return text\n",
    "\n",
    "\n",
    "# Untuk Proses Cleaning Data\n",
    "def preprocess(text):\n",
    "    text = lowercase(text) # 1\n",
    "    text = remove_unnecessary_char(text) # 2\n",
    "    text = remove_nonaplhanumeric(text) # 3\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_text(input_text):\n",
    "    try: \n",
    "        output_text = preprocess(input_text)\n",
    "        return output_text\n",
    "    except:\n",
    "        print(\"Text is unreadable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df.text.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita simpan teks ke dalam sebuah variabel\n",
    "data_preprocessed = df.text_clean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction finish\n"
     ]
    }
   ],
   "source": [
    "# to do Extraction feature, we use library \"Sklearn or scikit-learn\".\n",
    "# Sklearn is library for Machine Learning task.\n",
    "# \"CountVectorizer\" one of modul to do \"BoW\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# proced Feature Extraction\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(data_preprocessed)\n",
    "\n",
    "X = count_vect.transform(data_preprocessed)\n",
    "print (\"Feature Extraction finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 983)\t1\n",
      "  (0, 1095)\t1\n",
      "  (0, 1269)\t1\n",
      "  (0, 1687)\t1\n",
      "  (0, 1923)\t1\n",
      "  (0, 2308)\t1\n",
      "  (0, 3297)\t1\n",
      "  (0, 3415)\t1\n",
      "  (0, 3527)\t1\n",
      "  (0, 3588)\t1\n",
      "  (0, 4111)\t1\n",
      "  (0, 4168)\t2\n",
      "  (0, 4483)\t1\n",
      "  (0, 5899)\t1\n",
      "  (0, 6333)\t1\n",
      "  (0, 6375)\t1\n",
      "  (0, 6555)\t1\n",
      "  (0, 6617)\t1\n",
      "  (0, 6932)\t1\n",
      "  (0, 7138)\t1\n",
      "  (0, 8071)\t1\n",
      "  (0, 8228)\t1\n",
      "  (0, 8479)\t1\n",
      "  (0, 9316)\t1\n",
      "  (0, 9391)\t1\n",
      "  :\t:\n",
      "  (10999, 8666)\t1\n",
      "  (10999, 8831)\t1\n",
      "  (10999, 8833)\t2\n",
      "  (10999, 9101)\t1\n",
      "  (10999, 10342)\t1\n",
      "  (10999, 11105)\t3\n",
      "  (10999, 11701)\t1\n",
      "  (10999, 12534)\t1\n",
      "  (10999, 12535)\t1\n",
      "  (10999, 13383)\t1\n",
      "  (10999, 13420)\t1\n",
      "  (10999, 13632)\t1\n",
      "  (10999, 13678)\t1\n",
      "  (10999, 13701)\t2\n",
      "  (10999, 13837)\t1\n",
      "  (10999, 14161)\t1\n",
      "  (10999, 14227)\t1\n",
      "  (10999, 14374)\t1\n",
      "  (10999, 15449)\t1\n",
      "  (10999, 15627)\t1\n",
      "  (10999, 16096)\t1\n",
      "  (10999, 16132)\t1\n",
      "  (10999, 16303)\t1\n",
      "  (10999, 17102)\t3\n",
      "  (10999, 17134)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vect, open(\"feature(countvetorizer_nn).pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1         neutral\n",
       "2        positive\n",
       "3        positive\n",
       "4        negative\n",
       "           ...   \n",
       "10995    positive\n",
       "10996    positive\n",
       "10997     neutral\n",
       "10998    negative\n",
       "10999    positive\n",
       "Name: labels, Length: 11000, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classes = df['labels']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(classes).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print (\"Training selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model(countvetorizer_nn).pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79       703\n",
      "     neutral       0.78      0.68      0.72       240\n",
      "    positive       0.88      0.91      0.89      1257\n",
      "\n",
      "    accuracy                           0.84      2200\n",
      "   macro avg       0.82      0.79      0.80      2200\n",
      "weighted avg       0.84      0.84      0.84      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test = model.predict(X_test)\n",
    "\n",
    "print (\"Testing selesai\")\n",
    "\n",
    "print(classification_report(y_test, test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.79      0.78       680\n",
      "     neutral       0.78      0.61      0.68       239\n",
      "    positive       0.87      0.90      0.89      1281\n",
      "\n",
      "    accuracy                           0.83      2200\n",
      "   macro avg       0.81      0.77      0.78      2200\n",
      "weighted avg       0.83      0.83      0.83      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79       706\n",
      "     neutral       0.74      0.70      0.71       220\n",
      "    positive       0.89      0.91      0.90      1274\n",
      "\n",
      "    accuracy                           0.85      2200\n",
      "   macro avg       0.81      0.79      0.80      2200\n",
      "weighted avg       0.84      0.85      0.84      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.80      0.80       682\n",
      "     neutral       0.86      0.72      0.78       215\n",
      "    positive       0.89      0.92      0.90      1303\n",
      "\n",
      "    accuracy                           0.86      2200\n",
      "   macro avg       0.85      0.81      0.83      2200\n",
      "weighted avg       0.86      0.86      0.86      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.80      0.79       698\n",
      "     neutral       0.78      0.66      0.71       229\n",
      "    positive       0.88      0.90      0.89      1273\n",
      "\n",
      "    accuracy                           0.84      2200\n",
      "   macro avg       0.82      0.78      0.80      2200\n",
      "weighted avg       0.84      0.84      0.84      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79       670\n",
      "     neutral       0.79      0.65      0.71       245\n",
      "    positive       0.89      0.90      0.89      1285\n",
      "\n",
      "    accuracy                           0.84      2200\n",
      "   macro avg       0.82      0.79      0.80      2200\n",
      "weighted avg       0.84      0.84      0.84      2200\n",
      "\n",
      "======================================================\n",
      "Rata-rata Accuracy:  0.8449090909090909\n"
     ]
    }
   ],
   "source": [
    "# Untuk lebih menyakinkan lagi, kita juga bisa melakukan \"Cross Validation\"\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = classes\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X), start=1):\n",
    "\n",
    "    data_train   = X[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test    = X[data[1]]\n",
    "    target_test  = y[data[1]]\n",
    "\n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    preds = clf.predict(data_test)\n",
    "\n",
    "    # for the current fold only    \n",
    "    accuracy = accuracy_score(target_test,preds)\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(target_test,preds))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:\n",
      "\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "original_text =  '''\n",
    "Abid sangat suka\n",
    "'''\n",
    "\n",
    "# Feature Extraction\n",
    "text = count_vect.transform([process_text(original_text)])\n",
    "\n",
    "# Kita prediksi sentimennya\n",
    "result = model.predict(text)[0]\n",
    "print(\"Sentiment:\")\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saya suka makan nasi\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "def get_centiment_nn(original_text):\n",
    "    text = count_vect.transform([process_text(original_text)])\n",
    "    result = model.predict(text)[0]\n",
    "    return result\n",
    "\n",
    "print('Saya suka makan nasi')\n",
    "print(get_centiment_nn(\"Saya suka makan nasi\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6945fbbfcce95396e5b521c4600381f1cbc014f645d12c082997c649e7686935"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
